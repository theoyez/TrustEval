{"key": "PAPER:vaswani2017", "title": "Attention Is All You Need", "url": "https://arxiv.org/abs/1706.03762", "text": "The paper that introduced the Transformer architecture."}
{"key": "CARD:llama31", "title": "Llama 3.1 Model Card (summary)", "url": "https://ai.meta.com/llama/", "text": "Llama 3.1 family model card: context windows up to 128k tokens."}
{"key": "BENCH:mmlu", "title": "MMLU Benchmark (overview)", "url": "https://paperswithcode.com/dataset/mmlu", "text": "MMLU evaluates multitask language understanding across many subjects."}